name: Deploy ETL ADF

on:
  workflow_call:
    secrets:
      ACCOUNT_KEY:
        required: true

jobs:
  deploy:
    runs-on: self-hosted
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Exportar ACCOUNT_KEY al entorno
        shell: powershell
        run: |
          echo "ACCOUNT_KEY=${{ secrets.ACCOUNT_KEY }}" >> $env:GITHUB_ENV

      - name: Leer parámetros desde datosadf.json
        shell: powershell
        run: |
          $json = Get-Content "./datosadf.json" | ConvertFrom-Json
          echo "DATAFACTORY_NAME=$($json.dataFactoryName)" >> $env:GITHUB_ENV
          echo "RESOURCE_GROUP=$($json.resourceGroup)" >> $env:GITHUB_ENV

      # --- LINKED SERVICES ---
      - name: DEPLOY LINKED SERVICES
        shell: powershell
        run: |
          $linkedServiceFolder = "./linkedservices"
          $config = Get-Content "./datosadf.json" -Raw | ConvertFrom-Json
          $dataFactoryName = $config.dataFactoryName
          $rgName = $config.resourceGroup
          $accountKey = $env:ACCOUNT_KEY

          Get-ChildItem -Path $linkedServiceFolder -Filter '*.json' | ForEach-Object {
              $file = $_.FullName
              $name = $_.BaseName
              Write-Host "Preparando Linked Service: $name"

              $jsonContent = Get-Content -Raw $file
              $jsonContent = $jsonContent -replace '\$\{\{\s*secrets\.ACCOUNT_KEY\s*\}\}', $accountKey

              try { $parsed = $jsonContent | ConvertFrom-Json } catch {
                  Write-Error "JSON inválido en $file"
                  exit 1
              }

              $tempFile = [System.IO.Path]::GetTempFileName()
              $jsonContent | Set-Content -Path $tempFile -Encoding UTF8
              $absPath = Resolve-Path $tempFile

              az datafactory linked-service create `
                  --factory-name $dataFactoryName `
                  --resource-group $rgName `
                  --name $name `
                  --properties @$absPath

              az datafactory linked-service show `
                  --factory-name $dataFactoryName `
                  --resource-group $rgName `
                  --name $name

              Remove-Item $tempFile
          }

      # --- DATASETS ---
      - name: DEPLOY DATASETS
        shell: powershell
        run: |
          $datasetFolder = "./datasets"
          $config = Get-Content "./datosadf.json" -Raw | ConvertFrom-Json
          $dataFactoryName = $config.dataFactoryName
          $rgName = $config.resourceGroup

          Get-ChildItem -Path $datasetFolder -Filter '*.json' | ForEach-Object {
              $file = $_.FullName
              $name = $_.BaseName
              Write-Host "Preparando Dataset: $name"

              $jsonContent = Get-Content -Raw $file
              $jsonContent = $jsonContent -replace '\$\{\{\s*secrets\.ACCOUNT_KEY\s*\}\}', $env:ACCOUNT_KEY

              try { $parsed = $jsonContent | ConvertFrom-Json } catch {
                  Write-Error "JSON inválido en $file"
                  exit 1
              }

              $tempFile = [System.IO.Path]::GetTempFileName()
              $jsonContent | Set-Content -Path $tempFile -Encoding UTF8
              $absPath = Resolve-Path $tempFile

              az datafactory dataset create `
                  --factory-name $dataFactoryName `
                  --resource-group $rgName `
                  --name $name `
                  --properties @$absPath

              az datafactory dataset show `
                  --factory-name $dataFactoryName `
                  --resource-group $rgName `
                  --name $name

              Remove-Item $tempFile
          }

      # --- PIPELINES ---
      - name: DEPLOY PIPELINES - ETL DATAFACTORY
        shell: powershell
        run: |
          $pipelineFolder = "./pipelines"
          $config = Get-Content "./datosadf.json" -Raw | ConvertFrom-Json
          $dataFactoryName = $config.dataFactoryName
          $rgName = $config.resourceGroup

          Get-ChildItem -Path $pipelineFolder -Filter '*.json' | ForEach-Object {
              $file = $_.FullName
              $name = $_.BaseName
              Write-Host "Preparando Pipeline: $name"

              $jsonContent = Get-Content -Raw $file
              try { $parsed = $jsonContent | ConvertFrom-Json } catch {
                  Write-Error "JSON inválido en $file"
                  exit 1
              }

              $tempFile = [System.IO.Path]::GetTempFileName()
              $jsonContent | Set-Content -Path $tempFile -Encoding UTF8
              $absPath = Resolve-Path $tempFile

              cmd /c "az datafactory pipeline create --factory-name $dataFactoryName --resource-group $rgName --name $name --pipeline @$absPath"

              az datafactory pipeline show `
                  --factory-name $dataFactoryName `
                  --resource-group $rgName `
                  --name $name

              Remove-Item $tempFile
          }

      # --- RUN PIPELINES ---
      - name: RUN AND VERIFICATE ETL DATAFACTORY
        shell: powershell
        run: |
          $pipelineFolder = "./pipelines"
          $config = Get-Content "./datosadf.json" -Raw | ConvertFrom-Json
          $dataFactoryName = $config.dataFactoryName
          $rgName = $config.resourceGroup

          Get-ChildItem -Path $pipelineFolder -Filter '*.json' | ForEach-Object {
              $name = $_.BaseName
              Write-Host "Lanzando ejecución del pipeline: $name"

              $runId = az datafactory pipeline create-run `
                  --factory-name $dataFactoryName `
                  --resource-group $rgName `
                  --name $name `
                  --query runId -o tsv

              if (-not $runId) { Write-Error "No se pudo iniciar la ejecución del pipeline $name"; exit 1 }

              Write-Host "Pipeline $name iniciado con RunId: $runId"

              $status = "InProgress"
              while ($status -eq "InProgress") {
                  Start-Sleep -Seconds 20
                  $status = az datafactory pipeline-run show `
                      --factory-name $dataFactoryName `
                      --resource-group $rgName `
                      --run-id $runId `
                      --query status -o tsv
                  Write-Host "[$name] Estado actual: $status"
              }

              if ($status -eq "Succeeded") {
                  Write-Host "=============================="
                  Write-Host ("   PIPELINE {0} CORRIDO CON EXITO   " -f $name) 
                  Write-Host "=============================="
              } else {
                  Write-Host "#######################################" 
                  Write-Host ("  PIPELINE {0} TERMINO CON ESTADO: {1}" -f $name, $status)
                  Write-Host "#######################################"

                  Write-Host "Obteniendo logs detallados del pipeline..."
                  $logs = az datafactory activity-run query-by-pipeline-run `
                      --factory-name $dataFactoryName `
                      --resource-group $rgName `
                      --run-id $runId `
                      --last-updated-after (Get-Date).AddDays(-1).ToString("s") `
                      --last-updated-before (Get-Date).AddDays(1).ToString("s") `
                      -o json | ConvertFrom-Json

                  foreach ($activity in $logs.value) {
                      Write-Host "---------------------------------------"
                      Write-Host ("Actividad: {0}" -f $activity.activityName)
                      Write-Host ("Estado: {0}" -f $activity.status)
                      if ($activity.error) {
                          Write-Host ("Error: {0}" -f $activity.error.message) 
                      }
                      Write-Host "---------------------------------------"
                  }

                  exit 1
              }
          }
