name: Deployar Datafactory

on:
  push:
    branches:
      - etl_datafactory

jobs:
  login:
    uses: ./.github/workflows/credentials_azure.yml
    
  deploy:
    needs: login
    runs-on: self-hosted
    env:
      ARM_CLIENT_ID: ${{ needs.login.outputs.ARM_CLIENT_ID }}
      ARM_CLIENT_SECRET: ${{ needs.login.outputs.ARM_CLIENT_SECRET }}
      ARM_SUBSCRIPTION_ID: ${{ needs.login.outputs.ARM_SUBSCRIPTION_ID }}
      ARM_TENANT_ID: ${{ needs.login.outputs.ARM_TENANT_ID }}
      ACCOUNT_KEY: ${{ secrets.ACCOUNT_KEY }}
    steps:
      - name: Checkout del repositorio
        uses: actions/checkout@v4

      - name: Desplegar y verificar Linked Services
        shell: powershell
        run: |
          $linkedServiceFolder = "./linkedservices"
          $dataFactoryName = "DatafactoryGHA"
          $rgName = "MiResourceGroup"
          $accountKey = $env:ACCOUNT_KEY

          Get-ChildItem -Path $linkedServiceFolder -Filter '*.json' | ForEach-Object {
              $file = $_.FullName
              $name = $_.BaseName

              Write-Host "Preparando Linked Service: $name"

              # Leer JSON y reemplazar placeholder por el secret real
              $jsonContent = Get-Content -Raw $file
              $jsonContent = $jsonContent -replace '\$\{\{\s*secrets\.ACCOUNT_KEY\s*\}\}', $accountKey

              # Validar JSON
              try {
                  $parsed = $jsonContent | ConvertFrom-Json
              } catch {
                  Write-Error "JSON inválido en $file"
                  exit 1
              }

              # Guardar JSON temporal limpio
              $tempFile = [System.IO.Path]::GetTempFileName()
              $jsonContent | Set-Content -Path $tempFile -Encoding UTF8
              $absPath = Resolve-Path $tempFile

              Write-Host "Desplegando Linked Service: $name"

              # Crear linked service en Data Factory
              az datafactory linked-service create `
                  --factory-name $dataFactoryName `
                  --resource-group $rgName `
                  --name $name `
                  --properties @$absPath

              Write-Host "Verificando Linked Service: $name"
              az datafactory linked-service show `
                  --factory-name $dataFactoryName `
                  --resource-group $rgName `
                  --name $name

              Remove-Item $tempFile
          }

      - name: Desplegar y verificar Datasets
        shell: powershell
        run: |
          $datasetFolder = "./datasets"
          $dataFactoryName = "DatafactoryGHA"
          $rgName = "MiResourceGroup"

          Get-ChildItem -Path $datasetFolder -Filter '*.json' | ForEach-Object {
              $file = $_.FullName
              $name = $_.BaseName

              Write-Host "Preparando Dataset: $name"

              $jsonContent = Get-Content -Raw $file
              $jsonContent = $jsonContent -replace '\$\{\{\s*secrets\.ACCOUNT_KEY\s*\}\}', $env:ACCOUNT_KEY

              try {
                  $parsed = $jsonContent | ConvertFrom-Json
              } catch {
                  Write-Error "JSON inválido en $file"
                  exit 1
              }

              $tempFile = [System.IO.Path]::GetTempFileName()
              $jsonContent | Set-Content -Path $tempFile -Encoding UTF8
              $absPath = Resolve-Path $tempFile

              az datafactory dataset create `
                  --factory-name $dataFactoryName `
                  --resource-group $rgName `
                  --name $name `
                  --properties @$absPath

              az datafactory dataset show `
                  --factory-name $dataFactoryName `
                  --resource-group $rgName `
                  --name $name

              Remove-Item $tempFile
          }

      - name: Desplegar y verificar Pipelines
        shell: powershell
        run: |
          $pipelineFolder = "./pipelines"
          $dataFactoryName = "DatafactoryGHA"
          $rgName = "MiResourceGroup"

          Get-ChildItem -Path $pipelineFolder -Filter '*.json' | ForEach-Object {
              $file = $_.FullName
              $name = $_.BaseName

              Write-Host "Preparando Pipeline: $name"

              # Validar JSON
              $jsonContent = Get-Content -Raw $file
              try {
                  $parsed = $jsonContent | ConvertFrom-Json
              } catch {
                  Write-Error "JSON inválido en $file"
                  exit 1
              }

              # Guardar JSON temporal limpio
              $tempFile = [System.IO.Path]::GetTempFileName()
              $jsonContent | Set-Content -Path $tempFile -Encoding UTF8
              $absPath = Resolve-Path $tempFile

              Write-Host "Desplegando Pipeline: $name"

              # Usar cmd.exe para pasar el archivo JSON a Azure CLI
              cmd /c "az datafactory pipeline create --factory-name $dataFactoryName --resource-group $rgName --name $name --pipeline @$absPath"

              Write-Host "Verificando Pipeline: $name"
              az datafactory pipeline show `
                  --factory-name $dataFactoryName `
                  --resource-group $rgName `
                  --name $name

              Remove-Item $tempFile
          }

      - name: Ejecutar y verificar Pipelines
        shell: powershell
        run: |
          $pipelineFolder = "./pipelines"
          $dataFactoryName = "DatafactoryGHA"
          $rgName = "MiResourceGroup"

          Get-ChildItem -Path $pipelineFolder -Filter '*.json' | ForEach-Object {
              $name = $_.BaseName
              Write-Host "Lanzando ejecución del pipeline: $name"

              $runId = az datafactory pipeline create-run `
                  --factory-name $dataFactoryName `
                  --resource-group $rgName `
                  --name $name `
                  --query runId -o tsv

              if (-not $runId) {
                  Write-Error "No se pudo iniciar la ejecución del pipeline $name"
                  exit 1
              }

              Write-Host "Pipeline $name iniciado con RunId: $runId"

              # Monitorear el estado del pipeline
              $status = "InProgress"
              while ($status -eq "InProgress") {
                  Start-Sleep -Seconds 20
                  $status = az datafactory pipeline-run show `
                      --factory-name $dataFactoryName `
                      --resource-group $rgName `
                      --run-id $runId `
                      --query status -o tsv
                  Write-Host "[$name] Estado actual: $status"
              }

          if ($status -eq "Succeeded") {
              Write-Host ""
              Write-Host "==============================" -ForegroundColor Green
              Write-Host "   PIPELINE $name CORRIDO CON ÉXITO   " -ForegroundColor Green
              Write-Host "==============================" -ForegroundColor Green
              Write-Host ""
          } else {
              Write-Host ""
              Write-Host "#######################################" -ForegroundColor Red
              Write-Host "  PIPELINE $name TERMINÓ CON ESTADO: $status" -ForegroundColor Red
              Write-Host "#######################################" -ForegroundColor Red
              Write-Host ""
              exit 1
          }

          }
